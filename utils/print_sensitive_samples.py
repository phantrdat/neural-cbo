import torch
import cv2
import glob
import numpy as np
import pickle as pkl
import os
D = 49
RNUM = 200
func_name = 'SensitiveSample'
TRIAL  = 100
rdir =  f"results/{func_name}_DIM_{D}_ITERS_{RNUM}"
im_dir = 'asset/sensitive_sample_best'
def get_best_sample():
	algs = ['ADMMBO']
	best_list = {alg: [] for alg in algs}
	for alg in algs: 	
		print(alg)
		res_files = glob.glob(f'{rdir}/{alg}/*')
		print(res_files)
		best_val = []
		for pkl_file in res_files[:TRIAL]:
			Di  = pkl.load(open(pkl_file,'rb'))
			
			is_feasible =  [(torch.FloatTensor(v)<=0).all() for v in Di['constraint_values']]
			if alg == 'ConfigOpt' or alg == 'Neural-CBO':
				X  = Di['X_train'][9:][is_feasible]
			else:
				X  = Di['X_train'][is_feasible]
			best_feasible_idx = np.argmin(np.array(Di['optimal_values'])[is_feasible])
			best_val.append(np.min(np.array(Di['optimal_values'])[is_feasible]))

			best_list[alg].append(X[best_feasible_idx])	
		# best_list[alg] =[best_list[alg][i] for i in np.argsort(best_val)[:10]]
	return best_list
def to_img(img):
	
	if type(img).__name__== 'ndarray' or type(img).__name__== 'list':
				img = torch.Tensor(img)
	img = torch.reshape(img.cpu(), (7,7)).numpy()
	img = ((img*255) + 0.1307)*0.3081
	img = cv2.resize(img, (28,28))
	return img
	
if __name__=='__main__':
	best_list = get_best_sample()
	for k, samples in best_list.items():
		for i, v in enumerate(samples):
			# if type(v).__name__== 'ndarray' or type(v).__name__== 'list':
			# 	v = torch.Tensor(v)
			# v = torch.reshape(v.cpu(), (7,7)).numpy()
			# v = ((v*255) + 0.1307)*0.3081
			# v = cv2.resize(v, (28,28))
			v = to_img(v)
			if os.path.isdir(f"{im_dir}/{k}_{RNUM}") ==False:
				print(k)
				os.makedirs(f"{im_dir}/{k}_{RNUM}")

			cv2.imwrite(f"{im_dir}/{k}_{RNUM}/sensitive_{k}_{i}.jpg", v)
		
# 	imgs = [torch.tensor([-0.2368, -0.3683, -0.4242, -0.0412, -0.2143, -0.0165, -0.3591, -0.1232,
#         -0.1156,  2.3553,  2.8215,  0.9001, -0.4242, -0.2240,  0.0476,  2.3039,
#         -0.3779,  1.4225,  1.3431,  0.8585, -0.2759, -0.4242, -0.2465,  2.3765,
#          0.0687, -0.4242,  2.8215, -0.1968, -0.0172,  1.0130,  0.3514, -0.4242,
#         -0.2208,  2.8215, -0.0465, -0.4220,  0.0570,  2.2726,  2.8215,  1.2549,
#          2.1110, -0.0290, -0.3237, -0.4242,  0.0298, -0.1437, -0.4242, -0.4242,
#         -0.4242],   dtype=torch.float64), torch.tensor([-0.2803, -0.0925, -0.2840, -0.4242, -0.4242, -0.3860, -0.4242, -0.3779,
#         -0.1941, -0.0646,  2.5710,  2.6449, -0.3197, -0.4242, -0.4242, -0.0199,
#         -0.4242,  0.0676,  2.5463, -0.2202, -0.0407, -0.4242, -0.1134, -0.4242,
#          2.7502,  0.9161, -0.0663, -0.1176, -0.4242, -0.4109, -0.4242, -0.0791,
#          2.0872, -0.0993, -0.2911, -0.4242,  0.2938,  2.1352,  2.5606, -0.1635,
#         -0.0783, -0.3118, -0.4242, -0.1691, -0.2601,  0.0361, -0.0780,  0.0590,
#         -0.1843],   dtype=torch.float64), torch.tensor([-0.0987, -0.0860,  0.0046,  0.0098, -0.1713, -0.0135,  0.0264,  0.0480,
#         -0.4242, -0.4242, -0.2110, -0.4242, -0.0029, -0.4000, -0.0985,  1.6170,
#          2.8206,  1.7353,  1.7173,  2.0026, -0.0384, -0.1625,  1.3193, -0.1212,
#         -0.0175,  1.8282,  0.2270, -0.4242, -0.2616, -0.2827, -0.2471, -0.2643,
#          2.7535, -0.0527, -0.0930, -0.2389, -0.4233, -0.4113,  2.8215, -0.3226,
#         -0.2872, -0.2561, -0.0853, -0.2010, -0.3742,  1.7822, -0.1892,  0.0236,
#         -0.0864],   dtype=torch.float64), torch.tensor([-0.0607, -0.2131, -0.4094,  0.0689,  0.0201, -0.3802, -0.4242, -0.4242,
#         -0.2991, -0.2390, -0.2952, -0.3259, -0.3824, -0.1190, -0.1696, -0.2470,
#          2.5855,  0.8011,  2.2935, -0.2900, -0.1609, -0.4163, -0.2295,  0.7065,
#         -0.0136,  0.9077, -0.3001, -0.2692, -0.2209,  1.2015, -0.1881,  2.3711,
#          0.6942,  0.6847, -0.1507, -0.0546,  0.0346, -0.4211, -0.4195, -0.4242,
#         -0.2384,  0.0649, -0.1711, -0.4242, -0.1998, -0.3233, -0.4242, -0.3595,
#         -0.4242],   dtype=torch.float64), torch.tensor([-0.3032, -0.1792, -0.3835, -0.4242, -0.3989, -0.3644, -0.4242, -0.2883,
#         -0.3621, -0.1157, -0.3490,  2.8215, -0.4242, -0.4242, -0.2659, -0.0115,
#         -0.0391,  0.8499,  0.7533, -0.1218, -0.4242, -0.4242, -0.3656, -0.4242,
#          2.4949, -0.0587, -0.1998, -0.3589, -0.4242, -0.4242,  2.8215,  1.2356,
#          1.1765, -0.4242, -0.1035, -0.4242, -0.2446,  0.0726,  1.0792, -0.3987,
#         -0.3952, -0.1658, -0.4242, -0.4242, -0.0428, -0.1577,  0.0250, -0.4242,
#         -0.0485],   dtype=torch.float64), torch.tensor([-0.2567, -0.3887, -0.1831,  0.0504,  0.0206, -0.3510, -0.0492, -0.0558,
#          0.0579, -0.2241, -0.3638, -0.4242,  0.0668, -0.2974, -0.1062,  1.3322,
#          2.2545,  2.7451,  2.7248,  1.6377,  0.0090,  0.0240, -0.2949,  0.0274,
#         -0.2451,  2.8215, -0.1778, -0.1980, -0.4242, -0.2609, -0.0267,  2.5168,
#          0.8120, -0.1041, -0.4242,  0.0225, -0.0266, -0.2995,  2.8215,  0.0117,
#         -0.1675, -0.1288, -0.2806, -0.0796, -0.2186,  2.8215, -0.2297, -0.4023,
#         -0.4242],   dtype=torch.float64), torch.tensor([-0.2859, -0.2888, -0.2005, -0.2102, -0.3176, -0.4242, -0.4242, -0.0647,
#         -0.3297,  0.9634, -0.4040,  0.9032, -0.1214, -0.1229, -0.3486, -0.0179,
#          0.1452,  1.7403,  2.8215, -0.4125, -0.1808, -0.2845, -0.3070, -0.4242,
#          0.4228,  2.8215, -0.4242, -0.4242,  0.0083, -0.4242, -0.4153,  2.8215,
#          0.7204, -0.4242,  0.0655, -0.0140, -0.2172,  2.1321,  2.8215, -0.0550,
#         -0.4242, -0.0223, -0.4022, -0.4022,  1.2880, -0.0362, -0.3023, -0.0928,
#         -0.2722],   dtype=torch.float64), torch.tensor([-0.0042,  0.0689,  0.0469, -0.3547, -0.1493, -0.3504, -0.4242, -0.0998,
#         -0.3263,  0.0082,  0.6812,  2.8215,  0.8626, -0.0875, -0.4067, -0.1812,
#         -0.0764,  2.8215, -0.4242,  2.8215, -0.4242, -0.3687, -0.4161,  2.8215,
#          0.0150, -0.1867,  2.6737, -0.2053, -0.0461,  2.0009,  0.1443,  0.5535,
#          2.8058, -0.3483, -0.3897, -0.4242,  2.5943,  2.8215,  2.4689, -0.3006,
#         -0.4242, -0.0424, -0.2961, -0.4242,  0.0062,  0.0162, -0.1571,  0.0139,
#          0.0237],   dtype=torch.float64), torch.tensor([-0.1396, -0.0721, -0.0476, -0.4242,  0.0211, -0.0835, -0.2089, -0.0220,
#          0.0395, -0.0096,  1.2108,  2.6432,  1.0937, -0.4242,  0.0254, -0.4242,
#         -0.0358,  2.8215,  2.8215,  0.3938, -0.3187, -0.1234, -0.1236,  2.8215,
#          0.0496,  0.9707,  1.7052, -0.0239, -0.1062,  1.8320,  2.2347, -0.1684,
#          2.8215,  0.3990, -0.0966, -0.3208,  0.8526,  2.7033,  2.8215,  0.1731,
#         -0.0351, -0.0257, -0.0953, -0.0766, -0.2839,  0.0143, -0.1424,  0.0365,
#         -0.0508],   dtype=torch.float64), torch.tensor([-3.5385e-01, -7.0583e-02,  2.0623e-02, -4.2421e-01,  4.9365e-02,
#         -1.0582e-02,  2.1337e-02, -4.2421e-01, -1.9259e-01, -3.7208e-01,
#          3.2670e-01,  2.8215e+00, -4.2421e-01,  2.0555e-02, -2.0188e-01,
#         -4.2421e-01,  2.7370e+00,  1.2470e+00,  2.5214e-01, -2.5136e-02,
#         -3.8182e-01, -2.5428e-01, -3.3530e-01, -5.4945e-03,  4.2505e-01,
#          2.3648e+00, -1.5604e-01, -2.7279e-01, -4.7961e-02, -4.9347e-02,
#          8.3053e-01,  2.8215e+00,  3.3885e-01, -3.1304e-01, -4.2421e-01,
#          2.3063e-02, -2.4732e-03, -1.2500e-02,  1.0349e+00,  6.3111e-01,
#         -1.4666e-01, -7.5492e-03, -1.7891e-01,  1.1480e-02, -1.8070e-01,
#         -1.2872e-01, -4.2421e-01, -2.1918e-01, -1.0997e-01],  
#        dtype=torch.float64)]
# 	for i, x in enumerate(imgs):
# 		cv2.imwrite(f'{i}.jpg', to_img(x))